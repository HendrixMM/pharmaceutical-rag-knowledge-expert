#############################################
# Unified Environment Configuration (.env)  #
#############################################
#
# This single .env contains all keys/settings used by the app, tests, and CI.
# - Local runs: place this file at the repo root. dotenv loaders pick it up.
# - CI: store real secrets in CI secrets; keep placeholders here in Git.
# - Safety: This file includes extensive comments and placeholders by default.
#

# NVIDIA API Configuration
NVIDIA_API_KEY=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

# Optional: Other configuration
DOCS_FOLDER=Data/Docs
VECTOR_DB_PATH=./vector_db
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# -----------------------------------------------------------------------------
# NeMo Extraction (Document Ingestion) Configuration (inference only)
# -----------------------------------------------------------------------------
# Note: This project performs zero model fine-tuning. All options below control
# runtime inference behavior only (no training or weight updates).
# Master flag to enable NVIDIA NeMo/VLM-based extraction in the PDF loader.
# When false, the system uses a basic PDF extraction path.
ENABLE_NEMO_EXTRACTION=true

# Strategy for selecting the extraction backend when NeMo extraction is enabled:
# - auto: choose based on file characteristics (size/type) [recommended]
# - nemo: force NeMo Retriever Extraction (recommended default)
# - unstructured: use unstructured as a lightweight fallback (non-NVIDIA)
NEMO_EXTRACTION_STRATEGY=nemo

# Enable pharmaceutical-specific analysis and metadata enrichment on extracted text
# (drug names, dosages, clinical trial IDs, regulatory tags, etc.).
NEMO_PHARMACEUTICAL_ANALYSIS=true

# Chunking strategy applied by the NeMo extraction service before returning documents:
# - semantic: semantically coherent chunks (best quality, may be slower)
# - title: chunk by headings/titles
# - page: return page-level blocks (preserves legacy page-oriented behavior)
NEMO_CHUNK_STRATEGY=semantic

# Preserve tables and process images/charts during extraction. Enabling these
# improves structure fidelity but increases processing cost/time.
NEMO_PRESERVE_TABLES=true
NEMO_EXTRACT_IMAGES=true

# Strict NeMo mode: when true, disables all non-NVIDIA fallbacks
# (no PyPDF/Unstructured fallback if NeMo extraction fails)
NEMO_EXTRACTION_STRICT=false

# Application environment: set to 'production' to enforce strict NeMo mode
# (strict=true regardless of NEMO_EXTRACTION_STRICT). Use 'development' locally.
APP_ENV=development

# Notes:
# - When ENABLE_NEMO_EXTRACTION=false, none of the above settings alter behavior.
# - When true, failures may fall back to a non-NVIDIA path unless NEMO_EXTRACTION_STRICT=true.
# - Constructor arguments in code take precedence over these environment variables.

# Additional PDF metadata extraction controls
# Extract MeSH terms heuristically from PDF text (default: false)
ENABLE_MESH_FROM_PDF=false
# Cap lengths to keep metadata payloads tractable (characters)
DOC_METADATA_AUTHORS_MAX_LEN=500
DOC_METADATA_ABSTRACT_MAX_LEN=4000

# -----------------------------------------------------------------------------
# NeMo Model Selection Configuration (for three-step pipeline)
# -----------------------------------------------------------------------------
# Embedding model for the NeMo Retriever pipeline
# Options: nv-embedqa-e5-v5, nv-embedqa-mistral7b-v2, snowflake-arctic-embed-l
EMBEDDING_MODEL=nvidia/nv-embedqa-e5-v5

# Reranking model for the NeMo Retriever pipeline
# Options: nv-rerankqa-mistral4b-v3, llama-3_2-nemoretriever-500m-rerank-v2
RERANK_MODEL=llama-3_2-nemoretriever-500m-rerank-v2

# Vector Database Configuration
# Set to false to store all FAISS indexes in the base vector_db directory for compatibility
# with existing workflows. Set to true to use model-specific subdirectories (e.g.,
# ./vector_db/nvidia_llama-3.2-nemoretriever-1b-vlm-embed-v1), which prevents dimension
# mismatches when models change but may require a rebuild on first run.
VECTOR_DB_PER_MODEL=false

# Stats Collection Configuration
# Maximum number of documents to iterate for stats collection (default: 10000)
# Prevents performance issues with very large document stores
VECTOR_DB_STATS_MAX_ITERATIONS=10000
# Oversampling and fetch bounds for filtered similarity search
VECTOR_DB_MAX_FETCH_SIZE=10000
VECTOR_DB_MAX_OVERSAMPLE_ITERATIONS=3
VECTOR_DB_DEFAULT_OVERSAMPLE_MULTIPLIER=5
VECTOR_DB_MAX_OVERSAMPLE_MULTIPLIER=20
VECTOR_DB_MIN_TARGET_RESULTS=10

# PubMed Scraping Configuration
# Apify API token (https://console.apify.com)
APIFY_TOKEN=your_apify_token_here
# Cache directory for results
PUBMED_CACHE_DIR=./pubmed_cache
# Cache TTL in hours (default: 24)
PUBMED_CACHE_TTL_HOURS=24
# Query engine cache TTL in hours (default: 24)
QUERY_ENGINE_CACHE_TTL_HOURS=24
# PubMed cache behavior (optional)
# Cache empty results to avoid refetch loops
CACHE_EMPTY_RESULTS=false
# TTL for empty caches (<= PUBMED_CACHE_TTL_HOURS)
EMPTY_CACHE_TTL_SECONDS=300
# Advanced caching configuration (NCBI-compliant 24h caching)
# Toggle advanced caching (uses the NCBI-compliant cache manager when true)
ENABLE_ADVANCED_CACHING=true
# Enable the enhanced PubMed scraper wrapper (adds advanced caching + integrations)
ENABLE_ENHANCED_PUBMED_SCRAPER=false
CACHE_BACKEND=file
CACHE_METADATA_ENABLED=true
CACHE_STATISTICS_ENABLED=true
CACHE_CLEANUP_ENABLED=true
CACHE_CLEANUP_INTERVAL_HOURS=6
NCBI_CACHE_TTL_HOURS=24
NCBI_CACHE_GRACE_PERIOD_HOURS=2
CACHE_EMPTY_RESULTS_TTL_MINUTES=30
CACHE_ERROR_RESULTS_TTL_MINUTES=5
CACHE_MAX_SIZE_MB=1000
CACHE_MAX_ENTRIES=10000
CACHE_COMPRESSION_ENABLED=true
CACHE_WARMING_ENABLED=false
CACHE_RATE_LIMIT_INTEGRATION=true
CACHE_PHARMACEUTICAL_OPTIMIZATION=true
# Extra TTL hours applied to pharmaceutical queries (default 12)
PHARMA_TTL_BONUS_HOURS=12
# Opt-in migration flag that enables normalized cache keys for advanced caching
USE_NORMALIZED_CACHE_KEYS=false
# Allow serving stale results during grace period (default: true)
CACHE_ALLOW_STALE_WITHIN_GRACE=true
# Update hit_count and last_accessed_at on cache reads (default: true)
# Disabling reduces I/O but loses access analytics for cache entries
CACHE_WRITE_ON_ACCESS=true
# Use pretty-printed JSON for cache files (default: false)
# Enabling makes cache files human-readable but increases file size
CACHE_PRETTY_JSON=false
# Enforce minimum 24-hour TTLs for all cache entries (empty/error included)
STRICT_NCBI_TTL=false
# Mirror advanced cache writes back to the legacy root when normalized keys are disabled
MIRROR_TO_LEGACY_ROOT=false
# Remove legacy cache files after successful normalized-key migration
PRUNE_LEGACY_AFTER_MIGRATION=false
# Run background cleanup daemon alongside on-demand cleanup
CACHE_CLEANUP_DAEMON_ENABLED=false
# Enable PK-aware filtering in QueryEngine (default: false)
# When enabled, allows filtering by pharmacokinetic parameters similar to VectorDatabase
ENABLE_PK_FILTERING=false

# -----------------------------------------------------------------------------
# External Literature APIs (NCBI E-utilities and OpenAlex)
# -----------------------------------------------------------------------------
# NCBI E-utilities base URL (rarely changed). Used by src/pubmed_eutils_client.py
PUBMED_EUTILS_BASE_URL=https://eutils.ncbi.nlm.nih.gov/entrez/eutils
# Contact email for NCBI E-utilities (recommended by NCBI for identification/rate-limiting)
# Example: PUBMED_EMAIL=you@example.com
PUBMED_EMAIL=hendrixmoreau123@gmail.com
# Optional NCBI API key to increase rate limits (https://www.ncbi.nlm.nih.gov/books/NBK25497/)
PUBMED_EUTILS_API_KEY=55:PUBMED_EUTILS_API_KEY=b6860a46cdf303ac27f7db5dee1f9db9bf09

# OpenAlex API configuration (fallback literature source)
# Base URL (default: https://api.openalex.org)
OPENALEX_BASE_URL=https://api.openalex.org
# Contact email included via the 'mailto' query parameter per OpenAlex best practices
# Example: OPENALEX_EMAIL=you@example.com
OPENALEX_EMAIL=hendrixmoreau123@gmail.com

# Default handling for unknown species when species filters are applied
VECTOR_DB_SPECIES_UNKNOWN_DEFAULT=
QUERY_ENGINE_SPECIES_UNKNOWN_DEFAULT=
# Document cap for runtime drug-name extraction during filtering (default 200)
QUERY_ENGINE_RUNTIME_EXTRACTION_DOC_CAP=
# Query engine cache management (applies to in-process runtime helpers)
QUERY_ENGINE_MAX_CACHE_MB=1000
QUERY_ENGINE_CACHE_CLEANUP_THRESHOLD_MB=900
QUERY_ENGINE_CACHE_CHECK_FREQUENCY=50
# Try alternative EasyAPI input schemas if default fails

# EasyAPI PubMed Configuration
# Note: Requires EasyAPI subscription on Apify for enhanced PubMed scraping capabilities
EASYAPI_ACTOR_ID=easyapi/pubmed-search-scraper
DEFAULT_MAX_ITEMS=30
HARD_CAP_MAX_ITEMS=100
# Informational only - used for logging budget awareness, no enforcement
MONTHLY_BUDGET_LIMIT=19.99
EXTRACT_TAGS=true
# When rank=True, tag extraction is auto-enabled for ranking even if this is false (to keep scoring signals available)
# NOTE: With the default PRESERVE_PUBMED_ORDER=false, abstracts are fetched for non-ranking runs when USE_FULL_ABSTRACTS=true.
# This increases Apify usage cost; set USE_FULL_ABSTRACTS=false or PRESERVE_PUBMED_ORDER=true to skip abstracts on baseline crawls.
USE_FULL_ABSTRACTS=false
# Preserve-order runs (PRESERVE_PUBMED_ORDER=true with rank=False) skip abstracts to reduce cost; set rank=True or disable preserve order to include abstracts
# When ranking is enabled, abstracts are always requested regardless of USE_FULL_ABSTRACTS to keep scoring signals available.
# Study ranking is implemented. Set ENABLE_STUDY_RANKING=false or PRESERVE_PUBMED_ORDER=true to retain native PubMed order.
ENABLE_STUDY_RANKING=false
# Preserve original PubMed result ordering (disables ranking regardless of per-call rank overrides)
PRESERVE_PUBMED_ORDER=true
# Controls DOI and PMID deduplication (formerly ENABLE_PMID_DEDUPLICATION).
# Defaults to true (changed from false in legacy versions). This reduces result counts
# by removing duplicates but may surprise users expecting raw PubMed results.
# Set ENABLE_DEDUPLICATION=false to retain raw PubMed duplicates and match legacy behavior.
# The legacy ENABLE_PMID_DEDUPLICATION variable is deprecated in favour of this setting.
ENABLE_DEDUPLICATION=true
# Enable pharmaceutical query expansion with related terms
ENABLE_PHARMA_QUERY_ENHANCEMENT=true
# Enable pharmaceutical enhancement for advanced PubMed queries (field qualifiers, deep nesting, quoted phrases).
# Keeping this disabled avoids rewriting precise expert queries; set true only when expansion benefits outweigh the risk.
ENABLE_PHARMA_ENHANCE_ADVANCED=false
# Maximum number of enhancement clauses appended during pharmaceutical query expansion (set â‰¤ 0 for no cap)
PHARMA_MAX_TERMS=8
# Optional comma-separated terms appended to the pharmaceutical enhancement list (deduplicated case-insensitively)
PHARMA_EXTRA_TERMS=
# Override or extend MeSH qualifiers appended during pharmaceutical enhancement (comma-separated, case-insensitive dedupe)
PHARMA_MESH_QUALIFIERS=drug interactions[MeSH Terms],Cytochrome P-450 Enzyme System[MeSH]
# Enable addition of MeSH field-qualifier terms during pharmaceutical query enhancement (default: false)
# When enabled, appends terms like "drug interactions[MeSH Terms]" to expanded queries
# Set to true only when MeSH field qualifiers are needed for specific use cases
ENABLE_PHARMA_MESH_QUALIFIERS=false
# Maximum enhanced query length to prevent overly long URLs
MAX_QUERY_LENGTH=1800
# PubMed scraper provider variant identifier - specific implementation variant
# This maps to provider_detail in results, while provider remains 'apify' for backward compatibility
# Change this only when switching to a different Apify actor/implementation
SCRAPER_PROVIDER=apify-easyapi
# Comma-separated list of actor schemas to try in addition to searchUrls (EasyAPI actor supports searchUrls only)
EASYAPI_FALLBACK_SCHEMAS=
# Enable schema fallback (disabled for EasyAPI actor; set true only if alternate schemas are supported)
ENABLE_EASYAPI_SCHEMA_FALLBACK=false
# Toggle automatic schema fallback when the actor returns 4xx validation errors
EASYAPI_SMART_SCHEMA_FALLBACK=true

# EasyAPI Optional Flags Configuration
# Control whether to include tags in EasyAPI requests (defaults to true). When rank=True the scraper forces includeTags regardless of this setting.
#EASYAPI_INCLUDE_TAGS=true
# Control whether to include abstracts in EasyAPI requests (defaults to true)
#EASYAPI_INCLUDE_ABSTRACT=true
# Include tags in preserve-order runs when EXTRACT_TAGS=true (defaults to false)
# When enabled, tags are requested even when PRESERVE_PUBMED_ORDER=true to support metadata goals
INCLUDE_TAGS_WITH_PRESERVE_ORDER=true

# Study Ranking and Diversity Configuration
# Enable MinHash diversity filtering (defaults to true)
# When disabled, falls back to signature-based diversity filtering
ENABLE_MINHASH_DIVERSITY=true
# Number of permutations for MinHash diversity filtering (default: 128)
# Higher values increase accuracy but reduce performance. Range: 64-256
MINHASH_NUM_PERMUTATIONS=128
# Minimum input size to use MinHash method (default: 500)
# For smaller sets, signature-based diversity is used regardless of ENABLE_MINHASH_DIVERSITY
MINHASH_MIN_INPUT_SIZE=500
# Number of bands for LSH (Locality-Sensitive Hashing) (default: 16)
# Affects the threshold and performance of duplicate detection
MINHASH_NUM_BANDS=16
# LSH similarity threshold for candidate pair generation (default: 0.8)
# Lower values increase recall but reduce precision
MINHASH_LSH_THRESHOLD=0.8
# Optimize MinHash for memory usage (default: true)
# When enabled, uses more efficient data structures
MINHASH_OPTIMIZE_MEMORY=true
# Cache MinHash signatures for repeated runs (default: false)
# Can improve performance for multiple filtering passes on same data
MINHASH_CACHE_SIGNATURES=false

# Pharmaceutical Lexicon Configuration
# Curated lexicons are bundled in data/ directory for comprehensive drug detection
# Override with custom paths if needed (one drug name per line, # for comments)
DRUG_GENERIC_LEXICON=./data/drugs_generic.txt
DRUG_BRAND_LEXICON=./data/drugs_brand.txt
# Automatically create comprehensive drug lexicons if missing (requires AUTO_FETCH_DRUG_LEXICONS=true)
AUTO_FETCH_DRUG_LEXICONS=false
# CYP enzyme role mappings are automatically loaded from data/cyp_roles.csv

# -----------------------------------------------------------------------------
# Pharmaceutical Domain Overlay (lightweight, NeMo-friendly)
# -----------------------------------------------------------------------------
# When enabled, applies pharmaceutical-specific intelligence on top of extracted
# content without adding custom parsing pipelines. Keeps NeMo responsible for
# OCR/structure; this overlay adds synonym normalization, regulatory status tags,
# CYP risk scoring, evidence-level tags, species inference, and PK signal summary.
# Default: false for backward compatibility.
PHARMA_DOMAIN_OVERLAY=true

# Optional data sources for enhanced normalization (leave empty to skip):
# CSV columns: brand,generic,iupac,aliases  (aliases are pipe- or comma-separated)
DRUG_SYNONYMS_CSV=./data/drug_synonyms.csv
# JSON: list of objects with keys brand,generic,iupac,aliases
DRUG_SYNONYMS_JSON=

# Regulatory status reference table (optional). CSV columns:
# drug (or generic), agency, status, date, notes, aliases (optional)
REGULATORY_STATUS_CSV=./data/regulatory_status.csv

# Feature toggles for overlay sub-features (evaluated only when PHARMA_DOMAIN_OVERLAY=true)
PHARMA_ENABLE_REGULATORY_TAGS=true
PHARMA_ENABLE_SPECIES_INFERENCE=true
PHARMA_ENABLE_EVIDENCE_LEVEL=true

# Rate Limiting and Enhanced PubMed Scraper Configuration
# Enable NCBI-compliant rate limiting across PubMed scraping workflows (independent of ENABLE_ENHANCED_PUBMED_SCRAPER)
ENABLE_RATE_LIMITING=false
# Maximum allowed requests per second (NCBI recommends <= 3 req/s)
MAX_REQUESTS_PER_SECOND=3
# Maximum allowed requests per day before automatic throttling (0 or -1 disables the daily quota)
DAILY_REQUEST_LIMIT=500

# PubMed-specific rate limiting variables (for enhanced_config.py)
# Enable rate limiting for PubMed scraper
# Alternative: ENABLE_RATE_LIMITING (also supported)
ENABLE_PUBMED_RATE_LIMITING=true
# Rate limiting window in seconds
PUBMED_RATE_LIMIT_WINDOW_SECONDS=1
# Maximum requests per window (requests per second)
# Alternative: MAX_REQUESTS_PER_SECOND (also supported)
PUBMED_RATE_LIMIT_MAX_REQUESTS=3
# Toggle advanced detection of NCBI-recommended off-peak hours (9 PM - 5 AM ET)
ENABLE_OPTIMAL_TIMING_DETECTION=true
# Treat weekends as fully optimal for long-running jobs (set false to apply only nightly windows)
RATE_LIMIT_WEEKEND_OPTIMAL=true
# Logging verbosity for rate limiting diagnostics (DEBUG, INFO, WARNING, ERROR)
RATE_LIMITING_LOG_LEVEL=INFO
# Raise an error instead of waiting when the daily quota is exhausted
RATE_LIMIT_RAISE_ON_DAILY_LIMIT=false
# Maximum seconds to wait for daily reset before raising (default: 1 hour; blank disables the guard)
RATE_LIMIT_MAX_DAILY_WAIT_SECONDS=3600
# Share a single rate limiter across all scraper instances in the process
USE_PROCESS_WIDE_LIMITER=false

# Embedding Model Preference
# Preferred embedding model
EMBEDDING_MODEL_NAME=nvidia/llama-3.2-nemoretriever-1b-vlm-embed-v1
# Optional fallback when preferred model is unavailable
EMBEDDING_FALLBACK_MODEL=nvidia/nv-embed-v1
# Optional: override the NVIDIA embedding endpoint (defaults to https://integrate.api.nvidia.com/v1)
# EMBEDDING_BASE_URL=https://integrate.api.nvidia.com/v1
# Embedding runtime tuning (optional)
# Batch size for embedding requests
EMBEDDING_BATCH_SIZE=10
# Probe preferred model at startup (fallback if unavailable)
EMBEDDING_PROBE_ON_INIT=true
# Timeout for embedding probe requests in seconds (default: 30)
EMBEDDING_PROBE_TIMEOUT_SECONDS=30
# Timeout for embedding requests in seconds (default: 60)
EMBEDDING_TIMEOUT_SECONDS=60
# Control question-time preflight embedding (disabled by default for latency/cost).
# Set ENABLE_PREFLIGHT_EMBEDDING=true to force preflight; legacy DISABLE_PREFLIGHT_EMBEDDING=true also works.
# ENABLE_PREFLIGHT_EMBEDDING=false
# DISABLE_PREFLIGHT_EMBEDDING=true
# Force preflight embedding on first query and when vectorstore is missing (default: true)
# Set to false to suppress forced preflight even in per-model or first-run scenarios
FORCE_PREFLIGHT_ON_FIRST_QUERY=true
# Number of pages to scan when extracting PubMed metadata (default: 3)
PUBMED_SCAN_PAGES=3

# LLM Configuration
# LLM model for text generation (default: meta/llama-3.1-8b-instruct)
LLM_MODEL_NAME=meta/llama-3.1-8b-instruct
# Whether to append medical disclaimer to answer text (default: true)
# WARNING: Set to false ONLY if your UI renders RAGResponse.disclaimer separately to avoid duplicate disclaimers.
# This ensures compliance with requirements to include disclaimers in all responses.
APPEND_DISCLAIMER_IN_ANSWER=true

# Conservative Defaults Configuration
# The following settings are configured to maintain backward compatibility and optimize performance:
#
# ENABLE_STUDY_RANKING=false: Preserves original PubMed result ordering. Set to true to enable
#   AI-powered study ranking that reorders results based on quality and relevance.
#
# PRESERVE_PUBMED_ORDER=true: Maintains native PubMed sorting. Set to false to allow ranking
#   or other reordering of results.
#
# USE_FULL_ABSTRACTS=false: Reduces API costs by fetching only essential metadata. Set to true
#   to retrieve complete abstracts when detailed content analysis is needed.
#
# To enable enhanced features with higher costs:
# - Set ENABLE_STUDY_RANKING=true and PRESERVE_PUBMED_ORDER=false for AI-ranked results
# - Set USE_FULL_ABSTRACTS=true for complete abstract content (increases API usage)
#
# Impact of changes:
# - Result ordering: Conservative defaults maintain PubMed's native sort order
# - API costs: Defaults minimize Apify compute unit consumption
# - Performance: Optimized for faster response times with reduced data transfer

# RAG Agent PubMed Integration Configuration
# Master switch for all enhanced RAG features (default: false)
RAG_ENHANCED_FEATURES_ENABLED=false
# Enable PubMed integration in RAG agent (default: false)
ENABLE_RAG_PUBMED_INTEGRATION=false
# Enable hybrid local + PubMed querying (default: false)
RAG_PUBMED_HYBRID_MODE=false
# Use PubMed as fallback when local results insufficient (default: true)
RAG_PUBMED_FALLBACK_ENABLED=true
# Integrate PubMed cache with RAG query processing (default: true)
RAG_PUBMED_CACHE_INTEGRATION=true

# Enhanced Question Answering Configuration
# Maximum PubMed results to include in hybrid queries (default: 10)
RAG_PUBMED_MAX_EXTERNAL_RESULTS=10
# Minimum relevance score for including PubMed results (default: 0.7)
RAG_PUBMED_RELEVANCE_THRESHOLD=0.7
# Timeout for PubMed queries in RAG workflow (default: 30)
RAG_PUBMED_QUERY_TIMEOUT_SECONDS=30
# Enable pharmaceutical query enhancement in RAG (default: true)
RAG_PUBMED_ENABLE_QUERY_ENHANCEMENT=true
# Enable species filtering without pharmaceutical enrichment (default: false)
# When enabled, species filtering uses simple text inference instead of enriched metadata
ALLOW_SPECIES_FILTER_WITHOUT_ENRICHMENT=false

# Status Reporting and Monitoring
# Enable PubMed status in RAG system health (default: true)
ENABLE_RAG_PUBMED_STATUS_REPORTING=true
# Collect detailed metrics for PubMed integration (default: true)
RAG_PUBMED_METRICS_COLLECTION=true
# Enable performance logging for hybrid queries (default: false)
RAG_PUBMED_PERFORMANCE_LOGGING=false
# Include PubMed status in Streamlit dashboard (default: true)
RAG_PUBMED_DASHBOARD_INTEGRATION=true

# Feature Flag Management
# Enable gradual rollout mode with percentage-based activation (default: false)
RAG_PUBMED_GRADUAL_ROLLOUT=false
# Percentage of queries to use enhanced features (default: 0)
RAG_PUBMED_ROLLOUT_PERCENTAGE=0
# Enable beta features for testing (default: false)
RAG_PUBMED_BETA_MODE=false

# Integration Safety Settings
# Enable safe mode with conservative settings (default: true)
RAG_PUBMED_SAFE_MODE=true
# Error handling strategy: graceful, strict, silent (default: graceful)
RAG_PUBMED_ERROR_HANDLING=graceful
# Always fallback to local documents on PubMed errors (default: true)
RAG_PUBMED_FALLBACK_TO_LOCAL=true
# Strict mode for PubMed queries (default: false)
# When true, enables stricter validation and filtering for PubMed results
RAG_PUBMED_STRICT_MODE=false

# Cache and Performance Settings
# Prefetch PubMed cache on startup (default: false)
RAG_PUBMED_CACHE_PREFETCH=false
# Clean up PubMed cache on startup (default: false)
RAG_PUBMED_CACHE_CLEANUP=false

# -----------------------------------------------------------------------------
# Logging and Guardrails
# -----------------------------------------------------------------------------
# Global log verbosity (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO
# Enable medical guardrails (requires guardrails dependencies)
ENABLE_MEDICAL_GUARDRAILS=true
# Root directory for NeMo Guardrails configuration (optional)
GUARDRAILS_ROOT=
# Optional remote actions server for guardrails actions (leave empty to use bundled actions)
ACTIONS_SERVER_URL=

# -----------------------------------------------------------------------------
# MCP (Model Context Protocol) Documentation Service
# -----------------------------------------------------------------------------
# Microsoft Learn MCP server URL for live NeMo doc context
MCP_SERVER_URL=https://learn.microsoft.com/mcp/api/v1

# -----------------------------------------------------------------------------
# NVIDIA Build Free Tier (optional dev optimization)
# -----------------------------------------------------------------------------
# Enable free-tier awareness and console logging of approximate credit usage.
NVIDIA_BUILD_FREE_TIER=false
# Reduce request sizes and add jitter/backoff where applicable.
NVIDIA_RATE_LIMIT_AWARE=true
# Enable credit usage logging in tests and clients where supported.
NVIDIA_CREDITS_MONITORING=true
